{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os, csv, lucene\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from java.io import File\n",
    "from org.apache.lucene.analysis.standard import StandardAnalyzer\n",
    "from org.apache.lucene.index import DirectoryReader, IndexWriter, IndexWriterConfig\n",
    "from org.apache.lucene.queryparser.classic import QueryParser\n",
    "from org.apache.lucene.search import IndexSearcher\n",
    "from org.apache.lucene.document import Document, Field, FieldType, StringField, TextField\n",
    "from org.apache.lucene.store import SimpleFSDirectory, RAMDirectory\n",
    "from org.apache.lucene.util import Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jcc.JCCEnv at 0x7f9409c839c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lucene.initVM(vmargs=['-Djava.awt.headless=true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fsDir = SimpleFSDirectory(File(\"index\"))\n",
    "reader = DirectoryReader.open(fsDir)\n",
    "searcher = IndexSearcher(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyzer = StandardAnalyzer(Version.LUCENE_CURRENT)\n",
    "parser = QueryParser(Version.LUCENE_CURRENT, \"question\", analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = parser.parse('When athletes begin to exercise, their heart rates and respiration rates increase.  At what level of organization does the human body coordinate these functions?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.00224876404\n",
      "[u'When athletes begin to exercise, their heart rates and respiration rates increase. At what level of organization does the human body coordinate these functions?', u'at the system level', 6.002248764038086]\n",
      "[u'At what level of organization does life begin?', u'Cells', 0.7390643954277039]\n",
      "[u'at what level of organization does life begin', u'cell', 0.7390643954277039]\n",
      "[u'An increase in infflation does what to interest rates', u'Higher inflation = higher interest rates', 0.7244764566421509]\n",
      "[u'Level of Organization in the Human Body', u'Cell > Tissue > Organs > Organ Systems> Organisms', 0.671397864818573]\n",
      "[u'What is the largest level of organization in the human body?', u'the largest level of organization in the human body is the organ system.', 0.6668251752853394]\n",
      "[u'Birth rates rapidly decline,death rates continue to decline,and natural increase rates begin to moderate.', u'Stage 3: decreasing growth', 0.6202281713485718]\n",
      "[u'Birth rates rapidly decline, death rates continue to decline, and natural increase rates begin to moderate', u'Stage 3', 0.6202281713485718]\n",
      "[u'Birth rates rapidly decline, and death rates continue to decline, natural increase rates begin to moderate.', u'Stage 3', 0.6202281713485718]\n",
      "[u'Increase money supply does what to interest rates and what to GDP and inflation', u'Increase money supply = higher interest rates, lower GDP and inflation', 0.6166364550590515]\n"
     ]
    }
   ],
   "source": [
    "result = searcher.search(query, 10)\n",
    "print result.getMaxScore()\n",
    "scoreDocs = result.scoreDocs\n",
    "for scoreDoc in scoreDocs:\n",
    "    doc = searcher.doc(scoreDoc.doc)\n",
    "    print [doc.get(\"question\"), doc.get(\"answer\"), scoreDoc.score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0281300246716\n",
      "0.0281300246716\n",
      "0.271222114563\n",
      "0.0281300246716\n"
     ]
    }
   ],
   "source": [
    "# braindead way how to score similarity of two answers, but I didn't know Lucene any better\n",
    "def score_answer(answer, answerA):\n",
    "    directory = RAMDirectory()\n",
    "    analyzer = StandardAnalyzer(Version.LUCENE_CURRENT)\n",
    "    #analyzer = LimitTokenCountAnalyzer(analyzer, 10000)\n",
    "    config = IndexWriterConfig(Version.LUCENE_CURRENT, analyzer)\n",
    "    writer = IndexWriter(directory, config)\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add(Field(\"answer\", answer, TextField.TYPE_STORED))\n",
    "    writer.addDocument(doc)\n",
    "\n",
    "    writer.commit()\n",
    "    writer.close()\n",
    "    \n",
    "    reader = DirectoryReader.open(directory)\n",
    "    searcher = IndexSearcher(reader)\n",
    "\n",
    "    analyzer = StandardAnalyzer(Version.LUCENE_CURRENT)\n",
    "    parser = QueryParser(Version.LUCENE_CURRENT, \"answer\", analyzer)\n",
    "    query = parser.parse(QueryParser.escape(answerA))\n",
    "    result = searcher.search(query, 1)\n",
    "\n",
    "    scoreDocs = result.scoreDocs\n",
    "    #for scoreDoc in scoreDocs:\n",
    "    #    doc = searcher.doc(scoreDoc.doc)\n",
    "    #    print answerA, doc.get(\"answer\"), scoreDoc.score\n",
    "\n",
    "    if len(scoreDocs) > 0:\n",
    "        return result.getMaxScore()\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print score_answer(\"at the tissue level\", \"at the system level\")\n",
    "print score_answer(\"at the organ level\", \"at the system level\")\n",
    "print score_answer(\"at the system level\", \"at the system level\")\n",
    "print score_answer(\"at the cellular level\", \"at the system level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "Correct: 1238 Total: 2500 Accuracy: 0.495200\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "results = []\n",
    "with open(\"../data/training_set.tsv\") as f:\n",
    "    csv_reader = csv.reader(f, delimiter=\"\\t\", strict=True, quoting=csv.QUOTE_NONE)\n",
    "    header = next(csv_reader)  # ignore header\n",
    "    i = 0\n",
    "    for id, question, right, answerA, answerB, answerC, answerD in list(csv_reader):\n",
    "        query = parser.parse(QueryParser.escape(question))\n",
    "        result = searcher.search(query, 100)\n",
    "\n",
    "        #print question, answerA, answerB, answerC, answerD\n",
    "        \n",
    "        scoreA = 0\n",
    "        scoreB = 0\n",
    "        scoreC = 0\n",
    "        scoreD = 0\n",
    "        scoreDocs = result.scoreDocs\n",
    "        for scoreDoc in scoreDocs:\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            question = doc.get(\"question\")\n",
    "            answer = doc.get(\"answer\")\n",
    "            docscore = scoreDoc.score\n",
    "            #print question, answer, docscore\n",
    "\n",
    "            scoreA += docscore * score_answer(answer, answerA)\n",
    "            scoreB += docscore * score_answer(answer, answerB)\n",
    "            scoreC += docscore * score_answer(answer, answerC)\n",
    "            scoreD += docscore * score_answer(answer, answerD)\n",
    "        \n",
    "        scores = [scoreA, scoreB, scoreC, scoreD]\n",
    "        best = np.argmax(scores)\n",
    "        best = chr(ord('A') + best)\n",
    "        results.append([id, best] + scores)\n",
    "\n",
    "        #print scoreA, scoreB, scoreC, scoreD\n",
    "        #print right, best\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print i\n",
    "\n",
    "        if best == right:\n",
    "            correct += 1\n",
    "\n",
    "accuracy = float(correct) / len(results)\n",
    "print \"Correct: %d Total: %d Accuracy: %f\" % (correct, len(results), accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"lucene100_predictions_training.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in xrange(len(results)):\n",
    "        writer.writerow(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "results = []\n",
    "with open(\"../data/test_set.tsv\") as f:\n",
    "    csv_reader = csv.reader(f, delimiter=\"\\t\", strict=True, quoting=csv.QUOTE_NONE)\n",
    "    header = next(csv_reader)  # ignore header\n",
    "    i = 0\n",
    "    for id, question, answerA, answerB, answerC, answerD in list(csv_reader):\n",
    "        query = parser.parse(QueryParser.escape(question))\n",
    "        result = searcher.search(query, 100)\n",
    "\n",
    "        #print question, answerA, answerB, answerC, answerD\n",
    "        \n",
    "        scoreA = 0\n",
    "        scoreB = 0\n",
    "        scoreC = 0\n",
    "        scoreD = 0\n",
    "        scoreDocs = result.scoreDocs\n",
    "        for scoreDoc in scoreDocs:\n",
    "            doc = searcher.doc(scoreDoc.doc)\n",
    "            question = doc.get(\"question\")\n",
    "            answer = doc.get(\"answer\")\n",
    "            docscore = scoreDoc.score\n",
    "            #print question, answer, docscore\n",
    "\n",
    "            scoreA += docscore * score_answer(answer, answerA)\n",
    "            scoreB += docscore * score_answer(answer, answerB)\n",
    "            scoreC += docscore * score_answer(answer, answerC)\n",
    "            scoreD += docscore * score_answer(answer, answerD)\n",
    "        \n",
    "        scores = [scoreA, scoreB, scoreC, scoreD]\n",
    "        best = np.argmax(scores)\n",
    "        best = chr(ord('A') + best)\n",
    "        results.append([id, best] + scores)\n",
    "\n",
    "        #print scoreA, scoreB, scoreC, scoreD\n",
    "        #print right, best\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"lucene100_predictions_test.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "    for i in xrange(len(results)):\n",
    "        writer.writerow(results[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
