{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Graph, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "import theano.tensor as T\n",
    "from theano import function\n",
    "from itertools import islice\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(x, axis=None, keepdims=False):\n",
    "    return T.mean(x, axis=axis, keepdims=keepdims)\n",
    "\n",
    "def l2_normalize(x, axis):\n",
    "    norm = T.sqrt(T.sum(T.square(x), axis=axis, keepdims=True))\n",
    "    return x / norm\n",
    "\n",
    "def cosine_similarity(y_true, y_pred):\n",
    "    assert y_true.ndim == 2\n",
    "    assert y_pred.ndim == 2\n",
    "    y_true = l2_normalize(y_true, axis=1)\n",
    "    y_pred = l2_normalize(y_pred, axis=1)\n",
    "    return T.sum(y_true * y_pred, axis=1, keepdims=False)\n",
    "\n",
    "def cosine_ranking_loss(y_true, y_pred):\n",
    "    q = y_pred[0::3]\n",
    "    a_correct = y_pred[1::3]\n",
    "    a_incorrect = y_pred[2::3]\n",
    "\n",
    "    return mean(T.maximum(0., args.margin - cosine_similarity(q, a_correct) + cosine_similarity(q, a_incorrect)) - y_true[0]*0, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sequences(data_path, tokenizer, bidirectional):\n",
    "  while 1:\n",
    "    with open(data_path) as f:\n",
    "      for lines in islice(f, args.batch_size / 3):\n",
    "        print \"Lines:\", len(lines)\n",
    "        sequences = tokenizer.texts_to_sequences(lines)\n",
    "        print \"Sequences:\", len(sequences)\n",
    "        x = pad_sequences(sequences, maxlen=args.maxlen)\n",
    "        y = np.empty((x.shape[0], args.hidden_size))\n",
    "        print \"X,y:\", x.shape, y.shape\n",
    "        if bidirectional:\n",
    "          yield {'input': x, 'output': y}\n",
    "        else:\n",
    "          yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"model_path\")\n",
    "parser.add_argument(\"weights_path\")\n",
    "parser.add_argument(\"history_path\")\n",
    "parser.add_argument(\"--data_path\", default=\"/storage/hpc_tanel/allenAI/X_studystack_qa_cleaner_ranking_shuffled.txt\")\n",
    "parser.add_argument(\"--tokenizer_path\", default=\"model/tokenizer_studystack_full.pkl\")\n",
    "parser.add_argument(\"--maxlen\", type=int)\n",
    "parser.add_argument(\"--rnn\", choices=[\"LSTM\", \"GRU\"], default=\"GRU\")\n",
    "parser.add_argument(\"--embed_size\", type=int, default=300)\n",
    "parser.add_argument(\"--hidden_size\", type=int, default=1024)\n",
    "parser.add_argument(\"--layers\", type=int, default=1)\n",
    "parser.add_argument(\"--dropout\", type=float, default=0)\n",
    "parser.add_argument(\"--bidirectional\", action='store_true', default=False)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=300)\n",
    "parser.add_argument(\"--samples_per_epoch\", type=int, default=1000000)\n",
    "parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "parser.add_argument(\"--validation_split\", type=float, default=0)\n",
    "parser.add_argument(\"--optimizer\", choices=['adam', 'rmsprop'], default='adam')\n",
    "#parser.add_argument(\"--patience\", type=int, default=10)\n",
    "parser.add_argument(\"--verbose\", type=int, choices=[0, 1, 2], default=1)\n",
    "parser.add_argument(\"--margin\", type=float, default=0.1)\n",
    "parser.add_argument(\"--dense_layers\", type=int, default=0)\n",
    "parser.add_argument(\"--dense_activation\", choices=['relu','sigmoid','tanh'], default='relu')\n",
    "args = parser.parse_args(\"model/reference.json model/studystack_reference.hdf5 model/studystack_reference.pkl\".split())\n",
    "\n",
    "assert args.batch_size % 3 == 0, \"Batch size must be multiple of 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print \"Loading tokenizer...\"\n",
    "tokenizer = pickle.load(open(args.tokenizer_path, \"rb\"))\n",
    "vocab_size = tokenizer.nb_words+1 if tokenizer.nb_words else len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if args.rnn == 'GRU':\n",
    "  RNN = recurrent.GRU\n",
    "elif args.rnn == 'LSTM':\n",
    "  RNN = recurrent.LSTM\n",
    "else:\n",
    "  assert False, \"Invalid RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n",
      "--------------------------------------------------------------------------------\n",
      "Initial input shape: (None, 107149)\n",
      "--------------------------------------------------------------------------------\n",
      "Layer (name)                  Output Shape                  Param #             \n",
      "--------------------------------------------------------------------------------\n",
      "Embedding (embedding)         (None, None, 300)             32144700            \n",
      "GRU (gru)                     (None, 1024)                  4070400             \n",
      "--------------------------------------------------------------------------------\n",
      "Total params: 36215100\n",
      "--------------------------------------------------------------------------------\n",
      "Saving model architecture to model/reference.json\n"
     ]
    }
   ],
   "source": [
    "print \"Creating model...\"\n",
    "\n",
    "if args.bidirectional:\n",
    "  model = Graph()\n",
    "  model.add_input(name=\"input\", batch_input_shape=(args.batch_size,)+texts.shape[1:], dtype=\"uint\")\n",
    "  model.add_node(Embedding(vocab_size, args.embed_size, mask_zero=True), name=\"embed\", input='input')\n",
    "  for i in xrange(args.layers):\n",
    "    model.add_node(RNN(args.hidden_size, return_sequences=False if i + 1 == args.layers else True), \n",
    "        name='forward'+str(i+1), \n",
    "        input='embed' if i == 0 else 'dropout'+str(i) if args.dropout > 0 else None, \n",
    "        inputs=['forward'+str(i), 'backward'+str(i)] if i > 0 and args.dropout == 0 else [])\n",
    "    model.add_node(RNN(args.hidden_size, return_sequences=False if i + 1 == args.layers else True, go_backwards=True), \n",
    "        name='backward'+str(i+1), \n",
    "        input='embed' if i == 0 else 'dropout'+str(i) if args.dropout > 0 else None, \n",
    "        inputs=['forward'+str(i), 'backward'+str(i)] if i > 0 and args.dropout == 0 else [])\n",
    "    if args.dropout > 0:\n",
    "      model.add_node(Dropout(args.dropout), name='dropout'+str(i+1), inputs=['forward'+str(i+1), 'backward'+str(i+1)])\n",
    "  model.add_output(name='output',\n",
    "      input='dropout'+str(args.layers) if args.dropout > 0 else None,\n",
    "      inputs=['forward'+str(args.layers), 'backward'+str(args.layers)] if args.dropout == 0 else [])\n",
    "  assert args.dense_layers == 0, \"Bidirectional model doesn't support dense layers yet\"\n",
    "else:\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(vocab_size, args.embed_size, mask_zero=True))\n",
    "  for i in xrange(args.layers):\n",
    "    model.add(RNN(args.hidden_size, return_sequences=False if i + 1 == args.layers else True))\n",
    "    if args.dropout > 0:\n",
    "      model.add(Dropout(args.dropout))\n",
    "  for i in xrange(args.dense_layers):\n",
    "    if i + 1 == args.dense_layers:\n",
    "      model.add(Dense(args.hidden_size, activation='linear'))\n",
    "    else:\n",
    "      model.add(Dense(args.hidden_size, activation=args.dense_activation))\n",
    "\n",
    "model.summary()\n",
    "print \"Saving model architecture to\", args.model_path\n",
    "open(args.model_path, 'w').write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print \"Compiling model...\"\n",
    "if args.bidirectional:\n",
    "  model.compile(optimizer=args.optimizer, loss={'output': cosine_ranking_loss})\n",
    "else:\n",
    "  model.compile(optimizer=args.optimizer, loss=cosine_ranking_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint(filepath=args.weights_path, verbose=1, save_best_only=False)]\n",
    "generator = generate_sequences(args.data_path, tokenizer, args.bidirectional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 39) (300, 1024)\n"
     ]
    }
   ],
   "source": [
    "x,y = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 48) (300, 1024)\n",
      "(300, 48) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 35) (300, 1024)\n",
      "(300, 35) (300, 1024)\n"
     ]
    }
   ],
   "source": [
    "def generate_sequences(data_path, tokenizer, bidirectional):\n",
    "  while 1:\n",
    "    with open(data_path, \"r\") as f:\n",
    "      while True:\n",
    "        lines = list(islice(f, args.batch_size))\n",
    "        if not lines:\n",
    "            print \"End of file\"\n",
    "            break\n",
    "        print \"Lines:\", len(lines)\n",
    "        sequences = tokenizer.texts_to_sequences(lines)\n",
    "        print \"Sequences:\", len(sequences)\n",
    "        x = pad_sequences(sequences, maxlen=args.maxlen)\n",
    "        y = np.empty((x.shape[0], args.hidden_size))\n",
    "        print \"X,y:\", x.shape, y.shape\n",
    "        if bidirectional:\n",
    "          yield {'input': x, 'output': y}\n",
    "        else:\n",
    "          yield x, y\n",
    "\n",
    "generator = generate_sequences(args.data_path, tokenizer, args.bidirectional)\n",
    "x,y = next(generator)\n",
    "print x.shape, y.shape\n",
    "x,y = next(generator)\n",
    "print x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['between the visceral and parietal pericardium\\n', 'pericardial caivty\\n', 'patellar\\n', 'Consistently repeating a measurement.\\n', 'Precision\\n', 'Inference\\n', 'smallest units of matter\\n', 'atoms\\n', 'kneecap\\n', 'Flourens and Broca conducted research that demonstrated a connection between\\n']\n",
      "['mind and the brain\\n', 'stimulus and response\\n', 'The seven bones in the ankle\\n', 'Tarsals\\n', 'very localized responses in one organ (relaxed situations)\\n', 'a medium sized star; the center of our solar system\\n', 'Sun\\n', 'moon\\n', 'the passing of materials and energy from one organism to an other\\n', 'food chain\\n']\n"
     ]
    }
   ],
   "source": [
    "f = open(args.data_path, \"r\")\n",
    "next_n_lines = list(islice(f, 10))\n",
    "print next_n_lines\n",
    "next_n_lines = list(islice(f, 10))\n",
    "print next_n_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patellar\\n',\n",
       " 'Consistently repeating a measurement.\\n',\n",
       " 'Precision\\n',\n",
       " 'Inference\\n',\n",
       " 'smallest units of matter\\n',\n",
       " 'atoms\\n',\n",
       " 'kneecap\\n',\n",
       " 'Flourens and Broca conducted research that demonstrated a connection between\\n']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "Lines: 300\n",
      "Epoch 1/100\n",
      "Sequences: 300\n",
      "X,y: (300, 44) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 41) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 37) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 46) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 43) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 37) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 39) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 47) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 37) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 46) (300, 1024)\n",
      "Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 37) (300, 1024)\n",
      "     44/1000000 [..............................] - ETA: 24462s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 45) (300, 1024)\n",
      "     85/1000000 [..............................] - ETA: 22317s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 43) (300, 1024)\n",
      "    122/1000000 [..............................] - ETA: 23614s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 38) (300, 1024)\n",
      "    168/1000000 [..............................] - ETA: 23058s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 46) (300, 1024)\n",
      "    211/1000000 [..............................] - ETA: 22773s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 42) (300, 1024)\n",
      "    248/1000000 [..............................] - ETA: 23181s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 44) (300, 1024)\n",
      "    287/1000000 [..............................] - ETA: 22597s - loss: 0.1000Lines: 300\n",
      "Sequences: 300\n",
      "X,y: (300, 40) (300, 1024)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-37f9f09587ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   history = model.fit_generator(generator, samples_per_epoch=args.samples_per_epoch,\n\u001b[1;32m----> 7\u001b[1;33m       nb_epoch=args.epochs, verbose=args.verbose, callbacks=callbacks)\n\u001b[0m",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/Keras-0.3.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, show_accuracy, callbacks, validation_data, class_weight, nb_worker)\u001b[0m\n\u001b[0;32m    974\u001b[0m                                            \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                                            \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m                                            class_weight=class_weight)\n\u001b[0m\u001b[0;32m    977\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/Keras-0.3.1-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, X, y, accuracy, class_weight, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_with_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/Keras-0.3.1-py2.7.egg/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[0;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m--> 963\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    964\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hpc_tambet/venv_keras/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(node, args, outs)\u001b[0m\n\u001b[0;32m    950\u001b[0m                         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m                         self, node)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"Fitting model...\"\n",
    "if args.bidirectional:\n",
    "  history = model.fit_generator(generator, samples_per_epoch=args.samples_per_epoch,\n",
    "      nb_epoch=args.epochs, verbose=args.verbose, callbacks=callbacks)\n",
    "else:\n",
    "  history = model.fit_generator(generator, samples_per_epoch=args.samples_per_epoch,\n",
    "      nb_epoch=args.epochs, verbose=args.verbose, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
